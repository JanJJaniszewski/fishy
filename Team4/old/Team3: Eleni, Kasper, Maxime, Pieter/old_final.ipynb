{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is the final notebook. Please keep it clean as it will be shared with the other team members. \n",
    "\n",
    "Please keep the code as clean as possible, when having it in the final notebook as other players might use it too.\n",
    "\n",
    "Also, remember to take care of good commenting of the code as it will be shared with your coplayers later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot ad hoc CIFAR10 instances\n",
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "from scipy.misc import toimage\n",
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.display import Image\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from multi_gpu import make_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Read the data\n",
    "\n",
    "Read the file names from `../Data/Kaggle/train/*`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      image_name  fish_type_ALB  \\\n",
      "1524    ../Team 3/Zoomed train/YFT/img_06567.jpg              0   \n",
      "970     ../Team 3/Zoomed train/NoF/img_03423.jpg              0   \n",
      "453     ../Team 3/Zoomed train/YFT/img_00969.jpg              0   \n",
      "1988    ../Team 3/Zoomed train/NoF/img_02751.jpg              0   \n",
      "1277    ../Team 3/Zoomed train/ALB/img_04890.jpg              1   \n",
      "1432    ../Team 3/Zoomed train/ALB/img_00998.jpg              1   \n",
      "9       ../Team 3/Zoomed train/ALB/img_01374.jpg              1   \n",
      "2257    ../Team 3/Zoomed train/ALB/img_01033.jpg              1   \n",
      "546     ../Team 3/Zoomed train/ALB/img_05846.jpg              1   \n",
      "2237    ../Team 3/Zoomed train/NoF/img_07379.jpg              0   \n",
      "1560    ../Team 3/Zoomed train/ALB/img_00039.jpg              1   \n",
      "3515    ../Team 3/Zoomed train/YFT/img_02748.jpg              0   \n",
      "3294    ../Team 3/Zoomed train/BET/img_01440.jpg              0   \n",
      "1958    ../Team 3/Zoomed train/NoF/img_06256.jpg              0   \n",
      "1610  ../Team 3/Zoomed train/SHARK/img_04854.jpg              0   \n",
      "3744    ../Team 3/Zoomed train/ALB/img_01357.jpg              1   \n",
      "1790    ../Team 3/Zoomed train/DOL/img_06768.jpg              0   \n",
      "2427    ../Team 3/Zoomed train/ALB/img_06619.jpg              1   \n",
      "2040    ../Team 3/Zoomed train/YFT/img_01779.jpg              0   \n",
      "64      ../Team 3/Zoomed train/NoF/img_02272.jpg              0   \n",
      "2552  ../Team 3/Zoomed train/OTHER/img_02011.jpg              0   \n",
      "1740    ../Team 3/Zoomed train/ALB/img_05312.jpg              1   \n",
      "1791    ../Team 3/Zoomed train/YFT/img_07609.jpg              0   \n",
      "666     ../Team 3/Zoomed train/ALB/img_03335.jpg              1   \n",
      "317     ../Team 3/Zoomed train/ALB/img_02609.jpg              1   \n",
      "2416    ../Team 3/Zoomed train/ALB/img_03159.jpg              1   \n",
      "1252  ../Team 3/Zoomed train/OTHER/img_06699.jpg              0   \n",
      "3397    ../Team 3/Zoomed train/YFT/img_02550.jpg              0   \n",
      "2620    ../Team 3/Zoomed train/ALB/img_04320.jpg              1   \n",
      "164   ../Team 3/Zoomed train/OTHER/img_02715.jpg              0   \n",
      "...                                          ...            ...   \n",
      "2020    ../Team 3/Zoomed train/BET/img_01002.jpg              0   \n",
      "1603    ../Team 3/Zoomed train/ALB/img_01361.jpg              1   \n",
      "2514  ../Team 3/Zoomed train/SHARK/img_01307.jpg              0   \n",
      "1356    ../Team 3/Zoomed train/LAG/img_02415.jpg              0   \n",
      "1515  ../Team 3/Zoomed train/OTHER/img_00631.jpg              0   \n",
      "1434    ../Team 3/Zoomed train/ALB/img_03005.jpg              1   \n",
      "1990    ../Team 3/Zoomed train/ALB/img_02203.jpg              1   \n",
      "2474    ../Team 3/Zoomed train/ALB/img_03634.jpg              1   \n",
      "3617    ../Team 3/Zoomed train/ALB/img_06987.jpg              1   \n",
      "153     ../Team 3/Zoomed train/YFT/img_00641.jpg              0   \n",
      "3358    ../Team 3/Zoomed train/ALB/img_07892.jpg              1   \n",
      "2899    ../Team 3/Zoomed train/YFT/img_03062.jpg              0   \n",
      "1397    ../Team 3/Zoomed train/ALB/img_03662.jpg              1   \n",
      "1102    ../Team 3/Zoomed train/ALB/img_04330.jpg              1   \n",
      "3720  ../Team 3/Zoomed train/OTHER/img_05753.jpg              0   \n",
      "3038  ../Team 3/Zoomed train/SHARK/img_02080.jpg              0   \n",
      "1558    ../Team 3/Zoomed train/ALB/img_07851.jpg              1   \n",
      "779     ../Team 3/Zoomed train/YFT/img_06502.jpg              0   \n",
      "1962    ../Team 3/Zoomed train/ALB/img_02671.jpg              1   \n",
      "905   ../Team 3/Zoomed train/OTHER/img_01678.jpg              0   \n",
      "3361    ../Team 3/Zoomed train/ALB/img_07210.jpg              1   \n",
      "1533    ../Team 3/Zoomed train/ALB/img_00961.jpg              1   \n",
      "3470    ../Team 3/Zoomed train/ALB/img_00727.jpg              1   \n",
      "2152    ../Team 3/Zoomed train/ALB/img_04792.jpg              1   \n",
      "537     ../Team 3/Zoomed train/ALB/img_01454.jpg              1   \n",
      "2011    ../Team 3/Zoomed train/ALB/img_06950.jpg              1   \n",
      "1274    ../Team 3/Zoomed train/YFT/img_01456.jpg              0   \n",
      "289     ../Team 3/Zoomed train/ALB/img_00713.jpg              1   \n",
      "1656    ../Team 3/Zoomed train/ALB/img_05507.jpg              1   \n",
      "780     ../Team 3/Zoomed train/NoF/img_00068.jpg              0   \n",
      "\n",
      "      fish_type_ARK  fish_type_BET  fish_type_DOL  fish_type_HER  \\\n",
      "1524              0              0              0              0   \n",
      "970               0              0              0              0   \n",
      "453               0              0              0              0   \n",
      "1988              0              0              0              0   \n",
      "1277              0              0              0              0   \n",
      "1432              0              0              0              0   \n",
      "9                 0              0              0              0   \n",
      "2257              0              0              0              0   \n",
      "546               0              0              0              0   \n",
      "2237              0              0              0              0   \n",
      "1560              0              0              0              0   \n",
      "3515              0              0              0              0   \n",
      "3294              0              1              0              0   \n",
      "1958              0              0              0              0   \n",
      "1610              1              0              0              0   \n",
      "3744              0              0              0              0   \n",
      "1790              0              0              1              0   \n",
      "2427              0              0              0              0   \n",
      "2040              0              0              0              0   \n",
      "64                0              0              0              0   \n",
      "2552              0              0              0              1   \n",
      "1740              0              0              0              0   \n",
      "1791              0              0              0              0   \n",
      "666               0              0              0              0   \n",
      "317               0              0              0              0   \n",
      "2416              0              0              0              0   \n",
      "1252              0              0              0              1   \n",
      "3397              0              0              0              0   \n",
      "2620              0              0              0              0   \n",
      "164               0              0              0              1   \n",
      "...             ...            ...            ...            ...   \n",
      "2020              0              1              0              0   \n",
      "1603              0              0              0              0   \n",
      "2514              1              0              0              0   \n",
      "1356              0              0              0              0   \n",
      "1515              0              0              0              1   \n",
      "1434              0              0              0              0   \n",
      "1990              0              0              0              0   \n",
      "2474              0              0              0              0   \n",
      "3617              0              0              0              0   \n",
      "153               0              0              0              0   \n",
      "3358              0              0              0              0   \n",
      "2899              0              0              0              0   \n",
      "1397              0              0              0              0   \n",
      "1102              0              0              0              0   \n",
      "3720              0              0              0              1   \n",
      "3038              1              0              0              0   \n",
      "1558              0              0              0              0   \n",
      "779               0              0              0              0   \n",
      "1962              0              0              0              0   \n",
      "905               0              0              0              1   \n",
      "3361              0              0              0              0   \n",
      "1533              0              0              0              0   \n",
      "3470              0              0              0              0   \n",
      "2152              0              0              0              0   \n",
      "537               0              0              0              0   \n",
      "2011              0              0              0              0   \n",
      "1274              0              0              0              0   \n",
      "289               0              0              0              0   \n",
      "1656              0              0              0              0   \n",
      "780               0              0              0              0   \n",
      "\n",
      "      fish_type_LAG  fish_type_NoF  fish_type_YFT  \n",
      "1524              0              0              1  \n",
      "970               0              1              0  \n",
      "453               0              0              1  \n",
      "1988              0              1              0  \n",
      "1277              0              0              0  \n",
      "1432              0              0              0  \n",
      "9                 0              0              0  \n",
      "2257              0              0              0  \n",
      "546               0              0              0  \n",
      "2237              0              1              0  \n",
      "1560              0              0              0  \n",
      "3515              0              0              1  \n",
      "3294              0              0              0  \n",
      "1958              0              1              0  \n",
      "1610              0              0              0  \n",
      "3744              0              0              0  \n",
      "1790              0              0              0  \n",
      "2427              0              0              0  \n",
      "2040              0              0              1  \n",
      "64                0              1              0  \n",
      "2552              0              0              0  \n",
      "1740              0              0              0  \n",
      "1791              0              0              1  \n",
      "666               0              0              0  \n",
      "317               0              0              0  \n",
      "2416              0              0              0  \n",
      "1252              0              0              0  \n",
      "3397              0              0              1  \n",
      "2620              0              0              0  \n",
      "164               0              0              0  \n",
      "...             ...            ...            ...  \n",
      "2020              0              0              0  \n",
      "1603              0              0              0  \n",
      "2514              0              0              0  \n",
      "1356              1              0              0  \n",
      "1515              0              0              0  \n",
      "1434              0              0              0  \n",
      "1990              0              0              0  \n",
      "2474              0              0              0  \n",
      "3617              0              0              0  \n",
      "153               0              0              1  \n",
      "3358              0              0              0  \n",
      "2899              0              0              1  \n",
      "1397              0              0              0  \n",
      "1102              0              0              0  \n",
      "3720              0              0              0  \n",
      "3038              0              0              0  \n",
      "1558              0              0              0  \n",
      "779               0              0              1  \n",
      "1962              0              0              0  \n",
      "905               0              0              0  \n",
      "3361              0              0              0  \n",
      "1533              0              0              0  \n",
      "3470              0              0              0  \n",
      "2152              0              0              0  \n",
      "537               0              0              0  \n",
      "2011              0              0              0  \n",
      "1274              0              0              1  \n",
      "289               0              0              0  \n",
      "1656              0              0              0  \n",
      "780               0              1              0  \n",
      "\n",
      "[3777 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "# the folder path to the folder with all the fishies in there\n",
    "folders_path = '../Team 3/Zoomed train/*'\n",
    "\n",
    "# creating a dataframe with the columns below\n",
    "image_dict = {}\n",
    "\n",
    "# going through all folders and saving file names in dataframe so that order is always correct\n",
    "for foldername in glob.glob(folders_path):\n",
    "    for image_name in glob.glob(foldername + '/*.jpg'):\n",
    "        # getting image name and fish type and putting it in a dictionary\n",
    "        fish_type = foldername[-3:]\n",
    "        image_dict[image_name] = fish_type\n",
    "\n",
    "image_df = pd.DataFrame(image_dict.items(), columns = ['image_name', 'fish_type']).sample(frac=1) # random sampling\n",
    "dummy_df = pd.get_dummies(image_df, columns=['fish_type']) # dummify data\n",
    "print(dummy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Count of the image types\n",
    "#image_df.groupby('fish_type').count().sort_values('image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Manual preprocessing\n",
    "* Read the image from file\n",
    "* Resize it to (224, 224)\n",
    "* Set type to np.float (such that it can be reschaled to 0-1)\n",
    "* Rescale to 0-1\n",
    "* Subtract mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2352    img_01756.jpg\n",
      "3731    img_06025.jpg\n",
      "1178    img_06375.jpg\n",
      "2998    img_07193.jpg\n",
      "2588    img_00738.jpg\n",
      "2612    img_00899.jpg\n",
      "2035    img_03127.jpg\n",
      "2166    img_05413.jpg\n",
      "103     img_01346.jpg\n",
      "3667    img_02874.jpg\n",
      "2268    img_01850.jpg\n",
      "2284    img_03666.jpg\n",
      "583     img_01652.jpg\n",
      "3522    img_01521.jpg\n",
      "1420    img_06136.jpg\n",
      "3369    img_05832.jpg\n",
      "2733    img_04963.jpg\n",
      "2211    img_02134.jpg\n",
      "369     img_06086.jpg\n",
      "1117    img_00014.jpg\n",
      "2949    img_01297.jpg\n",
      "370     img_05762.jpg\n",
      "3671    img_02970.jpg\n",
      "111     img_06458.jpg\n",
      "1897    img_06022.jpg\n",
      "528     img_06773.jpg\n",
      "2719    img_05803.jpg\n",
      "3234    img_02893.jpg\n",
      "348     img_00863.jpg\n",
      "858     img_01858.jpg\n",
      "            ...      \n",
      "2020    img_01002.jpg\n",
      "1603    img_01361.jpg\n",
      "2514    img_01307.jpg\n",
      "1356    img_02415.jpg\n",
      "1515    img_00631.jpg\n",
      "1434    img_03005.jpg\n",
      "1990    img_02203.jpg\n",
      "2474    img_03634.jpg\n",
      "3617    img_06987.jpg\n",
      "153     img_00641.jpg\n",
      "3358    img_07892.jpg\n",
      "2899    img_03062.jpg\n",
      "1397    img_03662.jpg\n",
      "1102    img_04330.jpg\n",
      "3720    img_05753.jpg\n",
      "3038    img_02080.jpg\n",
      "1558    img_07851.jpg\n",
      "779     img_06502.jpg\n",
      "1962    img_02671.jpg\n",
      "905     img_01678.jpg\n",
      "3361    img_07210.jpg\n",
      "1533    img_00961.jpg\n",
      "3470    img_00727.jpg\n",
      "2152    img_04792.jpg\n",
      "537     img_01454.jpg\n",
      "2011    img_06950.jpg\n",
      "1274    img_01456.jpg\n",
      "289     img_00713.jpg\n",
      "1656    img_05507.jpg\n",
      "780     img_00068.jpg\n",
      "Name: image_name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "for filename in dummy_df.image_name:\n",
    "    img = cv2.imread(filename) # Read file    \n",
    "    img = cv2.resize(img, (224, 224)) # Resize image to 224 x 224 pixels (dont feel obliged to use this)\n",
    "    img = img.astype(np.float32) # Change to 32 bit floats (good for neural networks, other floats not as much making sense)\n",
    "\n",
    "    # \"Normalize\" images\n",
    "    for rgb_value in [0,1,2]:\n",
    "        img[:, :, rgb_value] = img[:, :, rgb_value] / 255.0 # 255 is the RGB maximum\n",
    "        img[:, :, rgb_value] -= numpy.mean(img[:, :, rgb_value])\n",
    "\n",
    "    img = img.transpose((2,0,1))\n",
    "    images.append(img)\n",
    "\n",
    "# X and y value and labels\n",
    "x = np.asarray(images)\n",
    "y = dummy_df.iloc[:,1:9].as_matrix()\n",
    "\n",
    "# For inspection: table, just to be sure that everything goes well\n",
    "labels = dummy_df.image_name.apply(lambda path: path[-13:])\n",
    "dummy_df['image_bytes'] = images\n",
    "\n",
    "split_no = int(len(x) * 0.9)\n",
    "\n",
    "x_train = x[:split_no]\n",
    "y_train = y[:split_no]\n",
    "labels_train = labels[:split_no]\n",
    "\n",
    "x_test = x[split_no:]\n",
    "y_test = y[split_no:]\n",
    "labels_test = labels[split_no:]\n",
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 8)\n"
     ]
    }
   ],
   "source": [
    "print y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Automated preprocessing: fish finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# do stuff here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(input=base_model.input, output=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "def feature_generator(x, reshape=False):\n",
    "    x = preprocess_input(x)\n",
    "    pred = model.predict(x)\n",
    "    if reshape:\n",
    "        pred = pred.reshape(pred.shape[0],-1)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f3b4e81ddb9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Disabled by default, takes ~5min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-df1c79725b2b>\u001b[0m in \u001b[0;36mfeature_generator\u001b[0;34m(x, reshape)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1217\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1219\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1601\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1602\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1603\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Disabled by default, takes ~5min\n",
    "feat = feature_generator(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Saving features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "numpy.save('featurescropped.npy', feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Loading features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "feat = numpy.load('features.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 512, 14, 14)\n"
     ]
    }
   ],
   "source": [
    "print feat.shape\n",
    "x_train_feat = feat[:split_no,:,:,:]\n",
    "x_train_feat.shape\n",
    "\n",
    "x_test_feat = feat[split_no:,:,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Top Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# build a classifier model to put on top of the convolutional model\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=(512, 14, 14)))\n",
    "top_model.add(Dense(256, activation='relu'))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(8, activation='sigmoid'))\n",
    "top_model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['binary_crossentropy'])\n",
    "top_model = make_parallel(top_model, 8)\n",
    "#top_model.fit(x_feat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3ca8aa476c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1066\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1068\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1069\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    964\u001b[0m                                check_batch_dim=True, batch_size=None):\n\u001b[1;32m    965\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'optimizer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 966\u001b[0;31m             raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    967\u001b[0m                                \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m                                'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "top_model.fit(x_train_feat, y_train, validation_data=(x_test_feat, y_test))\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "classes = model.predict_proba(x_test, batch_size=32)\n",
    "\n",
    "# get probability table\n",
    "proba_df = pd.DataFrame(classes)\n",
    "proba_df.columns = image_df.groupby('fish_type').count().index # workaround to get column names quickly and in right order\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print ' '\n",
    "proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
