{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is your private sketch-notebook. Do whatever you want with it. When code is ready to be developed, please just copy and paste it to the final notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot ad hoc CIFAR10 instances\n",
    "from keras.datasets import cifar10\n",
    "from matplotlib import pyplot\n",
    "from scipy.misc import toimage\n",
    "# Simple CNN model for CIFAR-10\n",
    "import numpy\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D, ZeroPadding2D\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from multi_gpu import make_parallel\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "FISH_DICTS = {\n",
    "    \"NoF\":0,\n",
    "    \"ALB\":1,\n",
    "    \"BET\":2,\n",
    "    \"DOL\":3,\n",
    "    \"LAG\":4,\n",
    "    \"SHARK\":5,\n",
    "    \"YFT\":6,\n",
    "    \"OTHER\":7    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the folder path to the folder with all the fishies in there\n",
    "folders_path = '../Data/Kaggle/train/*'\n",
    "\n",
    "# creating a dataframe with the columns below\n",
    "image_dict = {}\n",
    "\n",
    "# going through all folders and saving file names in dataframe so that order is always correct\n",
    "for foldername in glob.glob(folders_path):\n",
    "    for image_name in glob.glob(foldername + '/*.jpg'):\n",
    "        # getting image name and fish type and putting it in a dictionary\n",
    "        fish_type = foldername[-3:]\n",
    "        image_dict[image_name] = fish_type\n",
    "\n",
    "image_df = pd.DataFrame(image_dict.items(), columns = ['image_name', 'fish_type']).sample(frac=1) # random sampling\n",
    "dummy_df = pd.get_dummies(image_df, columns=['fish_type']) # dummify data\n",
    "\n",
    "count = 0 # count, to test the algorithm with 100 pictures\n",
    "images = []\n",
    "\n",
    "for filename in dummy_df.image_name:\n",
    "    img = image.load_img(filename, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)    \n",
    "    images.append(x)\n",
    "\n",
    "# X and y value and labels\n",
    "x = np.asarray(images)\n",
    "y = dummy_df.iloc[:,1:9].as_matrix()\n",
    "labels = dummy_df.image_name.apply(lambda path: path[-13:])\n",
    "\n",
    "# table, just to be sure that everything goes well\n",
    "dummy_df['image_bytes'] = images\n",
    "\n",
    "split_no = int(len(x) * 0.9)\n",
    "\n",
    "x_train = x[:split_no]\n",
    "y_train = y[:split_no]\n",
    "labels_train = labels[:split_no]\n",
    "\n",
    "x_test = x[split_no:]\n",
    "y_test = y[split_no:]\n",
    "labels_test = labels[split_no:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Smaller dataset for testing purposes!\n",
    "# dummy_df = dummy_df.iloc[0:101,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Image(url= \"https://kaggle2.blob.core.windows.net/competitions/kaggle/5568/media/species-ref-key.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Count of the image types\n",
    "#image_df.groupby('fish_type').count().sort_values('image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# count = 0 # count, to test the algorithm with 100 pictures\n",
    "# images = []\n",
    "\n",
    "# for filename in dummy_df.image_name:\n",
    "#     img = cv2.imread(filename) # Read file    \n",
    "#     img = cv2.resize(img, (224, 224)) # Resize image to 224 x 224 pixels (dont feel obliged to use this)\n",
    "#     img = img.astype(np.float32) # Change to 32 bit floats (good for neural networks, other floats not as much making sense)\n",
    "\n",
    "#     # \"Normalize\" images\n",
    "#     for rgb_value in [0,1,2]:\n",
    "#         img[:, :, rgb_value] = img[:, :, rgb_value] / 255.0 # 255 is the RGB maximum\n",
    "#         img[:, :, rgb_value] -= numpy.mean(img[:, :, rgb_value])\n",
    "\n",
    "# #     img = img.transpose((2,0,1))\n",
    "# #     img = image.load_img(filename, target_size=(224, 224))\n",
    "# #     x = image.img_to_array(img)\n",
    "# #     x = np.expand_dims(x, axis=0)\n",
    "# #     x = preprocess_input(x)\n",
    "\n",
    "#     images.append(img)\n",
    "\n",
    "# # X and y value and labels\n",
    "# x = np.asarray(images)\n",
    "# y = dummy_df.iloc[:,1:9].as_matrix()\n",
    "# labels = dummy_df.image_name.apply(lambda path: path[-13:])\n",
    "\n",
    "# # table, just to be sure that everything goes well\n",
    "# dummy_df['image_bytes'] = images\n",
    "# dummy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split_no = int(len(x) * 0.9)\n",
    "\n",
    "# x_train = x[:split_no]\n",
    "# y_train = y[:split_no]\n",
    "# labels_train = labels[:split_no]\n",
    "\n",
    "# x_test = x[split_no:]\n",
    "# y_test = y[split_no:]\n",
    "# labels_test = labels[split_no:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3399, 3, 224, 224)\n",
      "(378, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from keras.applications.resnet50 import ResNet50\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "# import numpy as np\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# import numpy as np\n",
    "# from keras.applications.vgg19 import VGG19\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg19 import preprocess_input\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "#model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a = model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 64, 7, 7)      294976      convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64, 7, 7)      0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 32, 7, 7)      18464       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 32, 3, 3)      0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 288)           0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           147968      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 8)             4104        dropout_2[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 465,512\n",
      "Trainable params: 465,512\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(64, 3, 3, input_shape=(512, 7, 7), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 100 # dont leave it like this, only for testing!\n",
    "lrate = 0.01\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.1, decay=decay, nesterov=True)\n",
    "model.compile(loss='hinge', optimizer=sgd, metrics=['binary_crossentropy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nieuw model (ipv model van Jan)\n",
    "# model = Sequential()\n",
    "# model.add(Convolution2D(32, 3, 3, input_shape=(512, 7, 7)))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(32, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# model.add(Convolution2D(64, 3, 3))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# # Compile model\n",
    "# epochs = 100 # dont leave it like this, only for testing!\n",
    "# lrate = 0.01\n",
    "# decay = lrate/epochs\n",
    "# sgd = SGD(lr=lrate, momentum=0.1, decay=decay, nesterov=True)\n",
    "# model.compile(loss='hinge', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import multi_gpu as mg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.preprocessing import image\n",
    "# from keras.applications.vgg16 import preprocess_input\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/applications/vgg16.py:137: UserWarning: You are using the TensorFlow backend, yet you are using the Theano image dimension ordering convention (`image_dim_ordering=\"th\"`). For best performance, set `image_dim_ordering=\"tf\"` in your Keras config at ~/.keras/keras.json.\n",
      "  warnings.warn('You are using the TensorFlow backend, yet you '\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 3, None, None) 0                                            \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv1 (Convolution2D)     (None, 64, None, None 1792        input_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "block1_conv2 (Convolution2D)     (None, 64, None, None 36928       block1_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)       (None, 64, None, None 0           block1_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv1 (Convolution2D)     (None, 128, None, Non 73856       block1_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block2_conv2 (Convolution2D)     (None, 128, None, Non 147584      block2_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)       (None, 128, None, Non 0           block2_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv1 (Convolution2D)     (None, 256, None, Non 295168      block2_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv2 (Convolution2D)     (None, 256, None, Non 590080      block3_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_conv3 (Convolution2D)     (None, 256, None, Non 590080      block3_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)       (None, 256, None, Non 0           block3_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv1 (Convolution2D)     (None, 512, None, Non 1180160     block3_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv2 (Convolution2D)     (None, 512, None, Non 2359808     block4_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_conv3 (Convolution2D)     (None, 512, None, Non 2359808     block4_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)       (None, 512, None, Non 0           block4_conv3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv1 (Convolution2D)     (None, 512, None, Non 2359808     block4_pool[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv2 (Convolution2D)     (None, 512, None, Non 2359808     block5_conv1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_conv3 (Convolution2D)     (None, 512, None, Non 2359808     block5_conv2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)       (None, 512, None, Non 0           block5_conv3[0][0]               \n",
      "====================================================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Awesome model\n",
    "x_train = base_model.predict(x_train)\n",
    "x_test = base_model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "mg.make_parallel(model,8)\n",
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), nb_epoch=epochs, batch_size=32*8)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "classes = model.predict_proba(x_test, batch_size=32)\n",
    "\n",
    "# get probability table\n",
    "proba_df = pd.DataFrame(classes)\n",
    "proba_df.columns = image_df.groupby('fish_type').count().index # workaround to get column names quickly and in right order\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print ' '\n",
    "proba_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proba_df['img_names'] = labels_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
