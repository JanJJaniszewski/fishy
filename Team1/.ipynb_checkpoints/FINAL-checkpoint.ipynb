{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Please enter your data\n",
    "\n",
    "UserName: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Imports and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports imported\n",
      "multi_gpu imported\n",
      "Vars initialized (FISH_DICTS, seed)\n"
     ]
    }
   ],
   "source": [
    "# Importing important stuff\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from First_start.imports import *\n",
    "from First_start.multi_gpu import *\n",
    "from First_start.init_vars import *\n",
    "from First_start.start_functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Explanation\n",
    "\n",
    "\n",
    "Sidenote:\n",
    "\n",
    "If you ever need more or new ideas, check out the kernels on fisheries-monitoring on Kaggle:\n",
    "\n",
    "https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Fish types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://kaggle2.blob.core.windows.net/competitions/kaggle/5568/media/species-ref-key.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://kaggle2.blob.core.windows.net/competitions/kaggle/5568/media/species-ref-key.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Important Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Make_parallel(model, gpu_count): You have 4 gpus, to use all four, use this function with your keras model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5652, 224, 224, 3) (5652, 8)\n"
     ]
    }
   ],
   "source": [
    "# Path to kaggle data folder\n",
    "paths = ['../Data/Kaggle/train/*', '../Data/Imagenet/*']\n",
    "\n",
    "# Get x and y variables\n",
    "# Model gives back:\n",
    "# x_train, y_train, x_test, y_test, image_df, dummy_df, but now it give no testset back cause test_size=0\n",
    "x_train, y_train, _, _, image_df, dummy_df = get_xy(folders_paths=paths, test_size=0.0,\n",
    "                                                              img_size=(224, 224), seed=seed)\n",
    "\n",
    "# Let's check the shape of those variables\n",
    "print (x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fish_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DOL</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LAG</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BET</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER</th>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoF</th>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARK</th>\n",
       "      <td>1203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YFT</th>\n",
       "      <td>1523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALB</th>\n",
       "      <td>1720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image\n",
       "fish_type       \n",
       "DOL          117\n",
       "LAG          125\n",
       "BET          200\n",
       "OTHER        299\n",
       "NoF          465\n",
       "SHARK       1203\n",
       "YFT         1523\n",
       "ALB         1720"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of the Kaggle fish types\n",
    "image_df.groupby('fish_type').count().sort_values('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fish Classification Methods\n",
    "\n",
    "## Neural Networks, VGG16 and VGG19:\n",
    "Some teams used self-built neural networks or the VGG16 or VGG19 pretrained networks. This method takes time although it is faster than before because we use GPUs now.\n",
    "\n",
    "The VGG16 or VGG19 models can be found here. Those are pretrained neural networks, mostly pretrained with the imagenet data.\n",
    "\n",
    "VGG16: https://gist.github.com/baraldilorenzo/07d7802847aaad0a35d3 \n",
    "\n",
    "VGG19: https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d\n",
    "\n",
    "Below, you can also find own neural networks built by the groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-98e8f0f06ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#VGG16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvgg16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx_train_vgg16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#x_test_vgg16 = vgg16.predict(x_test)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1272\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#VGG16\n",
    "vgg16 = VGG16(include_top=False)\n",
    "x_train_vgg16 = vgg16.predict(x_train)\n",
    "#x_test_vgg16 = vgg16.predict(x_test)\n",
    "\n",
    "#VGG19\n",
    "vgg19 = VGG19(weights='imagenet')\n",
    "if True: # If true, VGG19 will not use all layers but stop at layer block4_pooling\n",
    "    vgg19 = Model(input=vgg19.input, output=vgg19.get_layer('block4_pool').output)\n",
    "x_train_vgg19 = vgg19.predict(x_train)\n",
    "#x_test_vgg19 = vgg19.predict(x_test)\n",
    "\n",
    "# See the shape, to further work on it\n",
    "x_train_vgg19.shape, x_train_vgg16.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Neural Networks that were built last time by the team members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def model_standalone(optimizer, init):\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(3, 224, 224), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    # Compile model\n",
    "    epochs = 1 # dont leave it like this, only for testing!\n",
    "    lrate = 0.01\n",
    "    decay = lrate/epochs\n",
    "    sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'], init=init)\n",
    "    return model\n",
    "\n",
    "def model_VGG16_top(optimizer, init):\n",
    "    # Model to put on top of VGG16\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 3, 3, input_shape=(7, 7, 512), border_mode='same', activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu', border_mode='same', W_constraint=maxnorm(3)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu', W_constraint=maxnorm(3)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], init=init)\n",
    "    return model\n",
    "\n",
    "def model_VGG19_top(optimizer, init):\n",
    "    # Model to put on top of VGG16\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(14, 14, 512)))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(8, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'], init=init)\n",
    "    return model\n",
    "\n",
    "# Initialize variables\n",
    "param_grid = {'optimizer': ['adam', 'sgd'],\n",
    "              'nb_epoch': [2],\n",
    "              'batch_size': [5],\n",
    "              'init': ['uniform']\n",
    "             }\n",
    "\n",
    "model_base = model_VGG16_top\n",
    "x = x_train_vgg16 # right now, test is empty as test_size = 0 at the top function\n",
    "y = y_train # same for y, no test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "model = KerasClassifier(build_fn=model_base, verbose=0)\n",
    "grid = GridSearchCV(model, param_grid, )\n",
    "\n",
    "# Fit model\n",
    "results = grid.fit(x, y)\n",
    "\n",
    "# Analyzing\n",
    "means = results.cv_results_['mean_test_score']\n",
    "stds = results.cv_results_['std_test_score']\n",
    "params = results.cv_results_['params']\n",
    "\n",
    "print('Best: {}, using {}'.format(results.best_score_, results.best_params_))\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print('M={} (sd={}) with {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Fish Finding Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## SIFT Model\n",
    "\n",
    "Team2 developed a possibility to locate fish on a picture using the SIFT model. It seems to work fine. For further information, check the SIFT notebook of Team2 and ask the team2 members. Below is an example of the SIFT model. It matches the features of a picture and tries to match them with another picture to find the fish on the picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First, define a train and a test picture and load both pictures\n",
    "sift_path = '../Data/Kaggle/train/'\n",
    "train_pic = sift_path + 'LAG/img_00091.jpg'\n",
    "test_pic = sift_path + 'LAG/img_01512.jpg'\n",
    "train_pic = cv2.imread(train_pic,0)\n",
    "test_pic = cv2.imread(test_pic,0) \n",
    "\n",
    "# Creating a picture of the fish manually so that features of the fish can be found on this picture\n",
    "# (this is the left picture, that was manually found on the big picture, a picture of solely the fish)\n",
    "img_rows, img_cols= 350, 425\n",
    "template = np.zeros([ img_rows, img_cols], dtype='uint8') # initialisation of the template\n",
    "template[:, :] = train_pic[100:450,525:950] # I try multiple times to find the correct rectangle. \n",
    "\n",
    "# Plotting it just to check if the fish is really in this picture. Perfect, I would say!\n",
    "plt.subplots(figsize=(10, 7))\n",
    "plt.subplot(121),plt.imshow(template, cmap='gray') \n",
    "plt.subplot(122), plt.imshow(train_pic, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now, that we have manually made a picture of only the fish in the big picture, we can train the SIFT model,\n",
    "a feature matching model. The SIFT algorithm learns the features of the above picture and tries to match them\n",
    "the test picture and find the fish on this picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Copy the width and the height (assuming that this fish will also take about the same space in the picture)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "            'cv2.TM_CCORR_NORMED', 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "\n",
    "for meth in methods:\n",
    "     img = test_pic\n",
    "     method = eval(meth)\n",
    " \n",
    "     # Apply template Matching\n",
    "     res = cv2.matchTemplate(img,template,method)\n",
    "     min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    " \n",
    "     # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "     if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "         top_left = min_loc\n",
    "     else:\n",
    "         top_left = max_loc\n",
    "     bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    " \n",
    "     cv2.rectangle(img,top_left, bottom_right, 255, 2)\n",
    "     fig, ax = plt.subplots(figsize=(12, 7))\n",
    "     plt.subplot(121),plt.imshow(res,cmap = 'gray')\n",
    "     plt.title('Matching Result'), plt.xticks([]), plt.yticks([])\n",
    "     plt.subplot(122),plt.imshow(img,cmap = 'gray') #,aspect='auto'\n",
    "     plt.title('Detected Point'), plt.xticks([]), plt.yticks([])\n",
    "     plt.suptitle(meth)\n",
    " \n",
    "     plt.show()\n",
    "    \n",
    "# Below, we see the results of those algorithms. From the squares, we can see that the features of the fish\n",
    "# were detected in the most cases. For further information, please see the \"SIFT model\" notebook. Also, team2\n",
    "# suggested, that waves could interfere with the fish features and therefore, it is difficulty sometimes for the\n",
    "# model to find the right fish (see their attempts to find a shark with the SIFT model in the SIFT notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# How does evaluation work?\n",
    "Evaluation works easily and I can explain it to you guys. However, it is only possible two times per day!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate (only possible two times per day!)\n",
    "x_final_names, x_final = get_final_test(files_path='../Data/Kaggle/test1/*.jpg')\n",
    "\n",
    "# Predict outcome\n",
    "x_final_vgg16 = vgg16.predict(x_final)\n",
    "print(x_final_vgg16.shape)\n",
    "x_pred = results.predict_proba(x_final_vgg16)\n",
    "\n",
    "# Make pretty and save\n",
    "proba_df = pd.concat([pd.Series(x_final_names), pd.DataFrame(x_pred)], axis=1)\n",
    "proba_df.columns = [col.split('_')[-1] for col in dummy_df.columns]\n",
    "proba_df.image = proba_df.image.apply(lambda name: name.split('/')[-1])\n",
    "proba_df.to_csv('output_file.csv', index=False)\n",
    "proba_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
